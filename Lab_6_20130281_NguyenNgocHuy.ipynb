{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnhuy20130281/Lab_ML_NguyenNgocHuy/blob/main/Lab_6_20130281_NguyenNgocHuy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMzehe0sy5wr"
      },
      "source": [
        "# This lab is to deal with classification task using **Random Forests** and **Naïve Bayes** algorithms with/without **Feature Selection**. \n",
        "\n",
        "*   **Deadline: 23:59, 25/03/2023**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4nJmxp9zGX4"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoVWQ8AEyc-C",
        "outputId": "583e359e-7293-49ff-ea74-4ba166e18f23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import CategoricalNB, BernoulliNB, ComplementNB, GaussianNB, MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/Colab Notebooks'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNv07ARGzOUm"
      },
      "source": [
        "#Task 1. \n",
        "Task 1. Compare the performance of selected classification algorithms including **Random forest**, **NaiveBayes**, and **SVM** with **mnist** dataset based on **accuracy, precision, recall, f1** measures according to **without using selection feature** and **using selection feature**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOsg77IBzEyo",
        "outputId": "bf77826a-bbbf-4616-9112-4f80952b74f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+----------+-----------+--------+------+\n",
            "|   Algorithm   | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------+----------+-----------+--------+------+\n",
            "|      SVM      |   0.97   |    0.97   |  0.97  | 0.97 |\n",
            "| Random forest |   0.97   |    0.97   |  0.97  | 0.97 |\n",
            "|  Naive Bayes  |   0.84   |    0.84   |  0.84  | 0.84 |\n",
            "+---------------+----------+-----------+--------+------+\n",
            "+---------------+----------+-----------+--------+------+\n",
            "|   Algorithm   | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------+----------+-----------+--------+------+\n",
            "|      SVM      |   0.97   |    0.97   |  0.98  | 0.98 |\n",
            "| Random forest |   0.98   |    0.98   |  0.98  | 0.98 |\n",
            "|  Naive Bayes  |   0.88   |    0.88   |  0.88  | 0.88 |\n",
            "+---------------+----------+-----------+--------+------+\n"
          ]
        }
      ],
      "source": [
        "x = datasets.load_digits().data\n",
        "y = datasets.load_digits().target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(x_train, y_train)\n",
        "rf_pred = rf.predict(x_test)\n",
        "\n",
        "sVM = svm.SVC(kernel ='linear')\n",
        "sVM.fit(x_train, y_train)\n",
        "sVM_pred = sVM.predict(x_test)\n",
        "\n",
        "gauss = GaussianNB()\n",
        "gauss.fit(x_train, y_train)\n",
        "gauss_pred = gauss.predict(x_test)\n",
        "t = PrettyTable([\"Algorithm\",\"Accuracy\",\"Precision\", \"Recall\", \"F1\"])\n",
        "t.add_row([\"SVM\", round(accuracy_score(y_test, sVM_pred), 2), \n",
        "           round(precision_score(y_test, sVM_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, sVM_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, sVM_pred,average='macro'), 2)])\n",
        "t.add_row([\"Random forest\", round(accuracy_score(y_test, rf_pred), 2), \n",
        "           round(precision_score(y_test, rf_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, rf_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, rf_pred,average='macro'), 2)])\n",
        "t.add_row([\"Naive Bayes\", round(accuracy_score(y_test, gauss_pred), 2), \n",
        "           round(precision_score(y_test, gauss_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, gauss_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, gauss_pred,average='macro'), 2)])\n",
        "print(t)\n",
        "\n",
        "x_new = SelectKBest(chi2, k=32).fit_transform(x, y)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_new, y, test_size=0.3)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(x_train, y_train)\n",
        "rf_pred = rf.predict(x_test)\n",
        "\n",
        "sVM = svm.SVC(kernel ='linear')\n",
        "sVM.fit(x_train, y_train)\n",
        "sVM_pred = sVM.predict(x_test)\n",
        "\n",
        "gauss = GaussianNB()\n",
        "gauss.fit(x_train, y_train)\n",
        "gauss_pred = gauss.predict(x_test)\n",
        "t = PrettyTable([\"Algorithm\",\"Accuracy\",\"Precision\", \"Recall\", \"F1\"])\n",
        "t.add_row([\"SVM\", round(accuracy_score(y_test, sVM_pred), 2), \n",
        "           round(precision_score(y_test, sVM_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, sVM_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, sVM_pred,average='macro'), 2)])\n",
        "t.add_row([\"Random forest\", round(accuracy_score(y_test, rf_pred), 2), \n",
        "           round(precision_score(y_test, rf_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, rf_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, rf_pred,average='macro'), 2)])\n",
        "t.add_row([\"Naive Bayes\", round(accuracy_score(y_test, gauss_pred), 2), \n",
        "           round(precision_score(y_test, gauss_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, gauss_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, gauss_pred,average='macro'), 2)])\n",
        "print(t)\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b52OPWPD2afi"
      },
      "source": [
        "#Task 2. \n",
        "For given bank dataset (bank.csv) having the following attributes :\n",
        "1.\t**age** (numeric)\n",
        "2.\t**job** : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3.\t**marital** : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4.\t**education** (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5.\t**default**: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6.\t**housing**: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7.\t**loan**: has personal loan? (categorical: 'no','yes','unknown')\n",
        "8.\t**contact**: contact communication type (categorical: 'cellular','telephone')\n",
        "9.\t**month**: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "10.\t**day_of_week**: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11.\t**duration**: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "12.\t**campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13.\t**pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14.\t**previous**: number of contacts performed before this campaign and for this client (numeric)\n",
        "15.\t**poutcome**: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "Output variable (desired target):\n",
        "16.\t**y**. has the client subscribed a term deposit? (binary: 'yes','no')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGxhAvs6rFTQ"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"bank.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q89LEvT7dqaZ"
      },
      "source": [
        "#3.1. Apply StandardScaler() function to columns that contains numerical data ('age', 'balance', 'day', 'campaign', 'pdays', 'previous')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vx3mfIidu4P"
      },
      "outputs": [],
      "source": [
        "dataset[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']] = StandardScaler().fit_transform(dataset[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7acR0TxdvY8"
      },
      "source": [
        "#3.2. Apply Encode Categorical Value (OneHotEncoder) to transfrom categorical data to numerical data ('job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egtgBmAtd0um",
        "outputId": "541d1125-c205-4c8d-e3eb-8e650d567ff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
            "       'deposit', 'job_admin.', 'job_blue-collar', 'job_entrepreneur',\n",
            "       'job_housemaid', 'job_management', 'job_retired', 'job_self-employed',\n",
            "       'job_services', 'job_student', 'job_technician', 'job_unemployed',\n",
            "       'job_unknown', 'marital_divorced', 'marital_married', 'marital_single',\n",
            "       'education_primary', 'education_secondary', 'education_tertiary',\n",
            "       'education_unknown', 'default_no', 'default_yes', 'housing_no',\n",
            "       'housing_yes', 'loan_no', 'loan_yes', 'contact_cellular',\n",
            "       'contact_telephone', 'contact_unknown', 'month_apr', 'month_aug',\n",
            "       'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun',\n",
            "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
            "       'poutcome_failure', 'poutcome_other', 'poutcome_success',\n",
            "       'poutcome_unknown'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "encode = OneHotEncoder()\n",
        "encode.fit(dataset[['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']])\n",
        "encoded = encode.transform(dataset[['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']]).toarray()\n",
        "new_df = pd.DataFrame(encoded, columns=encode.get_feature_names_out(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']))\n",
        "dataset = pd.concat([dataset, new_df], axis=1)\n",
        "dataset = dataset.drop(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome'], axis=1)\n",
        "\n",
        "print(dataset.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2Si6d69d1nh"
      },
      "source": [
        "#3.3. Apply **Decision tree, Random forest, kNN, NaïveBayes** to preproceed dataset in the previous steps. Then compare the obtained results using **accuracy, precision, recall, f1** measures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ouil-cf_d8jW",
        "outputId": "ddcab862-e98d-409c-d56a-ca077c78db6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+----------+-----------+--------+------+\n",
            "|   Algorithm   | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------+----------+-----------+--------+------+\n",
            "|      SVM      |   0.83   |    0.83   |  0.83  | 0.83 |\n",
            "| Random forest |   0.85   |    0.85   |  0.85  | 0.85 |\n",
            "|  Naive Bayes  |   0.72   |    0.72   |  0.71  | 0.71 |\n",
            "+---------------+----------+-----------+--------+------+\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dataset.drop('deposit', axis=1), dataset['deposit'], test_size=0.3)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(x_train, y_train)\n",
        "rf_pred = rf.predict(x_test)\n",
        "\n",
        "sVM = svm.SVC(kernel ='linear')\n",
        "sVM.fit(x_train, y_train)\n",
        "sVM_pred = sVM.predict(x_test)\n",
        "\n",
        "gauss = GaussianNB()\n",
        "gauss.fit(x_train, y_train)\n",
        "gauss_pred = gauss.predict(x_test)\n",
        "t = PrettyTable([\"Algorithm\",\"Accuracy\",\"Precision\", \"Recall\", \"F1\"])\n",
        "t.add_row([\"SVM\", round(accuracy_score(y_test, sVM_pred), 2), \n",
        "           round(precision_score(y_test, sVM_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, sVM_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, sVM_pred,average='macro'), 2)])\n",
        "t.add_row([\"Random forest\", round(accuracy_score(y_test, rf_pred), 2), \n",
        "           round(precision_score(y_test, rf_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, rf_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, rf_pred,average='macro'), 2)])\n",
        "t.add_row([\"Naive Bayes\", round(accuracy_score(y_test, gauss_pred), 2), \n",
        "           round(precision_score(y_test, gauss_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, gauss_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, gauss_pred,average='macro'), 2)])\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SweVRB4meApP"
      },
      "source": [
        "#3.4. Using selection feature to above dataset, then compare the classification results with those in Task 2.3. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seFBhqCSeC7C",
        "outputId": "424f8430-1bbb-413f-bce1-31c47fd5095d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+----------+-----------+--------+------+\n",
            "|   Algorithm   | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------+----------+-----------+--------+------+\n",
            "|      SVM      |   0.81   |    0.81   |  0.8   | 0.81 |\n",
            "| Random forest |   0.83   |    0.83   |  0.83  | 0.83 |\n",
            "|  Naive Bayes  |   0.72   |    0.72   |  0.71  | 0.71 |\n",
            "+---------------+----------+-----------+--------+------+\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.feature_selection  import SelectFromModel\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "importances_sort = np.argsort(importances)[::-1]\n",
        "\n",
        "select = SelectFromModel(rf, threshold=0.011)\n",
        "x_train = select.fit_transform(x_train, y_train)\n",
        "x_test = select.transform(x_test)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(x_train, y_train)\n",
        "rf_pred = rf.predict(x_test)\n",
        "\n",
        "sVM = svm.SVC(kernel ='linear')\n",
        "sVM.fit(x_train, y_train)\n",
        "sVM_pred = sVM.predict(x_test)\n",
        "\n",
        "gauss = GaussianNB()\n",
        "gauss.fit(x_train, y_train)\n",
        "gauss_pred = gauss.predict(x_test)\n",
        "t = PrettyTable([\"Algorithm\",\"Accuracy\",\"Precision\", \"Recall\", \"F1\"])\n",
        "t.add_row([\"SVM\", round(accuracy_score(y_test, sVM_pred), 2), \n",
        "           round(precision_score(y_test, sVM_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, sVM_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, sVM_pred,average='macro'), 2)])\n",
        "t.add_row([\"Random forest\", round(accuracy_score(y_test, rf_pred), 2), \n",
        "           round(precision_score(y_test, rf_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, rf_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, rf_pred,average='macro'), 2)])\n",
        "t.add_row([\"Naive Bayes\", round(accuracy_score(y_test, gauss_pred), 2), \n",
        "           round(precision_score(y_test, gauss_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, gauss_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, gauss_pred,average='macro'), 2)])\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      },
      "source": [
        "#Task 4. \n",
        "For a given dataset in the Lab #5 (**credit card dataset**), perform feature selection and thencompare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression, SVM, Random Forest and NaiveBayes) based on accuracy, precision, recall, f1 measures.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rw_-8FIf2KxW",
        "outputId": "54a90d83-4a30-454e-fa12-33ddac6238e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+----------+-----------+--------+------+\n",
            "|   Algorithm   | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------+----------+-----------+--------+------+\n",
            "|      SVM      |   1.0    |    1.0    |  0.91  | 0.92 |\n",
            "| Random forest |   1.0    |    1.0    |  0.91  | 0.94 |\n",
            "|  Naive Bayes  |   0.98   |    0.98   |  0.93  | 0.56 |\n",
            "|   Logicstic   |   1.0    |    1.0    |  0.81  | 0.87 |\n",
            "| Decision Tree |   1.0    |    1.0    |  0.88  | 0.87 |\n",
            "|      kNN      |   1.0    |    1.0    |  0.9   | 0.93 |\n",
            "+---------------+----------+-----------+--------+------+\n"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_csv(\"creditcard.csv\")\n",
        "\n",
        "x = dataset.drop('Class', axis=1)\n",
        "y = dataset['Class']\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.3)\n",
        "\n",
        "lr = LogisticRegression(random_state = 0)\n",
        "lr.fit(x_train, y_train)\n",
        "lr_pred = lr.predict(x_test)\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(x_train, y_train)\n",
        "tree_pred = tree.predict(x_test)\n",
        "\n",
        "\n",
        "kNN = KNeighborsClassifier(n_neighbors=5)\n",
        "kNN.fit(x_train, y_train)\n",
        "kNN_pred = kNN.predict(x_test)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(x_train, y_train)\n",
        "rf_pred = rf.predict(x_test)\n",
        "\n",
        "sVM = svm.SVC(kernel ='linear')\n",
        "sVM.fit(x_train, y_train)\n",
        "sVM_pred = sVM.predict(x_test)\n",
        "\n",
        "gauss = GaussianNB()\n",
        "gauss.fit(x_train, y_train)\n",
        "gauss_pred = gauss.predict(x_test)\n",
        "\n",
        "t = PrettyTable([\"Algorithm\",\"Accuracy\",\"Precision\", \"Recall\", \"F1\"])\n",
        "t.add_row([\"SVM\", round(accuracy_score(y_test, sVM_pred), 2), \n",
        "           round(precision_score(y_test, sVM_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, sVM_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, sVM_pred,average='macro'), 2)])\n",
        "t.add_row([\"Random forest\", round(accuracy_score(y_test, rf_pred), 2), \n",
        "           round(precision_score(y_test, rf_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, rf_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, rf_pred,average='macro'), 2)])\n",
        "t.add_row([\"Naive Bayes\", round(accuracy_score(y_test, gauss_pred), 2), \n",
        "           round(precision_score(y_test, gauss_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, gauss_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, gauss_pred,average='macro'), 2)])\n",
        "t.add_row([\"Logicstic\", round(accuracy_score(y_test, lr_pred), 2), \n",
        "           round(precision_score(y_test, lr_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, lr_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, lr_pred,average='macro'), 2)])\n",
        "t.add_row([\"Decision Tree\", round(accuracy_score(y_test, tree_pred), 2), \n",
        "           round(precision_score(y_test, tree_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, tree_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, tree_pred,average='macro'), 2)])\n",
        "t.add_row([\"kNN\", round(accuracy_score(y_test, kNN_pred), 2), \n",
        "           round(precision_score(y_test, kNN_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, kNN_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, kNN_pred,average='macro'), 2)])\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok7RGkea_b7n"
      },
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}